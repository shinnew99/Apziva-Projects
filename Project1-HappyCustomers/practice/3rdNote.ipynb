{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1lyLnTtC3N3K2jy_nPqYk4x3muGINGQ2u",
      "authorship_tag": "ABX9TyOd/M9DMYBVeYfPtUvl6U0M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinnew99/Apziva-Projects/blob/main/Project1-HappyCustomers/3rdNote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3rd Suggestions:\n",
        "1. Experiment with other models that Lazy suggested <br>\n",
        "2. When Modeling:<br>\n",
        "1) For the hyper parameter tuning, use 'Hyper OPT', which is Bayesian Technique (let's see whether it works well). Remember Recall > F-1 Score is important <br>\n",
        "2) From Ensembling (allows us to see multiple models to benefit from different models strength), use Stacking, and Voting Classifier (1. Hard/2. Soft, try both on the models that I will be selecting) <br>\n",
        "3. Recursive Feature Elimination, which is very straightforward and available in Scikit. It automatically picks me the top-k (ranking of the) features."
      ],
      "metadata": {
        "id": "SwTpvECKrBqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA_jxDT2MPXA",
        "outputId": "4cc64b30-e7e9-4aad-f05b-acf8bec0ff83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazypredict"
      ],
      "metadata": {
        "id": "tx3tRxo9nJGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d664f53d-f16f-4f24-c807-5ad7d70c07de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.1.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.66.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.4.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.4.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.5.0)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost->lazypredict)\n",
            "  Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
            "Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
            "Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, lazypredict\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.22.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lazypredict-0.2.12 nvidia-nccl-cu12-2.22.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
        "from hyperopt.pyll.base import scope\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "BS7KWN_6k6hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75014121-a759-490f-86f5-6504273b99c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Apziva/ACME-HappinessSurvey2020.csv')\n",
        "\n",
        "data = df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6']]\n",
        "target = df[['Y']]"
      ],
      "metadata": {
        "id": "9DnaoAjbnVoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed = random.randint(1000, 9999)\n",
        "seed = 6245\n",
        "print(seed)  # 6245, XGB - racll (0.88) for class 0\n",
        "\n",
        "# run quite a few times, monitor each time to find out better seeds and whether it impacts higher perfermance on class 0, recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykSparmFnagR",
        "outputId": "082e689f-6806-4647-90b3-e0fdd1186290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=seed)"
      ],
      "metadata": {
        "id": "gvYKWo3JnkYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "print(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85NXeg_3noBS",
        "outputId": "0251f11d-4dd2-46f5-d697-9b1981717bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:02<00:00, 11.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 51, number of negative: 49\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 31\n",
            "[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.510000 -> initscore=0.040005\n",
            "[LightGBM] [Info] Start training from score 0.040005\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
            "Model                                                                           \n",
            "LabelPropagation                   0.69               0.71     0.71      0.70   \n",
            "LabelSpreading                     0.69               0.71     0.71      0.70   \n",
            "BernoulliNB                        0.62               0.69     0.69      0.62   \n",
            "LGBMClassifier                     0.58               0.66     0.66      0.58   \n",
            "BaggingClassifier                  0.65               0.65     0.65      0.67   \n",
            "DecisionTreeClassifier             0.65               0.65     0.65      0.67   \n",
            "QuadraticDiscriminantAnalysis      0.58               0.62     0.62      0.59   \n",
            "NuSVC                              0.65               0.61     0.61      0.66   \n",
            "GaussianNB                         0.54               0.60     0.60      0.55   \n",
            "SVC                                0.54               0.60     0.60      0.55   \n",
            "NearestCentroid                    0.54               0.60     0.60      0.55   \n",
            "ExtraTreeClassifier                0.58               0.56     0.56      0.59   \n",
            "RidgeClassifierCV                  0.50               0.53     0.53      0.52   \n",
            "LinearSVC                          0.50               0.53     0.53      0.52   \n",
            "CalibratedClassifierCV             0.50               0.53     0.53      0.52   \n",
            "AdaBoostClassifier                 0.50               0.53     0.53      0.52   \n",
            "RidgeClassifier                    0.50               0.53     0.53      0.52   \n",
            "LogisticRegression                 0.50               0.53     0.53      0.52   \n",
            "LinearDiscriminantAnalysis         0.50               0.53     0.53      0.52   \n",
            "XGBClassifier                      0.54               0.53     0.53      0.56   \n",
            "RandomForestClassifier             0.54               0.53     0.53      0.56   \n",
            "DummyClassifier                    0.69               0.50     0.50      0.57   \n",
            "ExtraTreesClassifier               0.54               0.49     0.49      0.55   \n",
            "SGDClassifier                      0.35               0.49     0.49      0.27   \n",
            "Perceptron                         0.50               0.47     0.47      0.52   \n",
            "KNeighborsClassifier               0.42               0.34     0.34      0.43   \n",
            "PassiveAggressiveClassifier        0.27               0.30     0.30      0.28   \n",
            "\n",
            "                               Time Taken  \n",
            "Model                                      \n",
            "LabelPropagation                     0.04  \n",
            "LabelSpreading                       0.04  \n",
            "BernoulliNB                          0.04  \n",
            "LGBMClassifier                       0.11  \n",
            "BaggingClassifier                    0.08  \n",
            "DecisionTreeClassifier               0.03  \n",
            "QuadraticDiscriminantAnalysis        0.07  \n",
            "NuSVC                                0.05  \n",
            "GaussianNB                           0.03  \n",
            "SVC                                  0.06  \n",
            "NearestCentroid                      0.04  \n",
            "ExtraTreeClassifier                  0.03  \n",
            "RidgeClassifierCV                    0.04  \n",
            "LinearSVC                            0.04  \n",
            "CalibratedClassifierCV               0.09  \n",
            "AdaBoostClassifier                   0.18  \n",
            "RidgeClassifier                      0.05  \n",
            "LogisticRegression                   0.04  \n",
            "LinearDiscriminantAnalysis           0.06  \n",
            "XGBClassifier                        0.47  \n",
            "RandomForestClassifier               0.41  \n",
            "DummyClassifier                      0.03  \n",
            "ExtraTreesClassifier                 0.20  \n",
            "SGDClassifier                        0.03  \n",
            "Perceptron                           0.08  \n",
            "KNeighborsClassifier                 0.04  \n",
            "PassiveAggressiveClassifier          0.07  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursive Feature Elimination (RFE)\n",
        "def perform_rfe(model, X_train, y_train, k):\n",
        "    rfe = RFE(estimator=model, n_features_to_select=k)\n",
        "    fit = rfe.fit(X_train, y_train.values.ravel())\n",
        "    return fit"
      ],
      "metadata": {
        "id": "OwUgjw5nnqyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-k features based on RFE\n",
        "rfe_model = LogisticRegression()  # make sure I'm using the same seeds for the models\n",
        "fit = perform_rfe(rfe_model, X_train, y_train, 3)  # selecting top 3 features for simplicity  # I need to print out the name of the features, so that I can recommend to the companies\n",
        "# print out the ranking\n",
        "X_train_rfe = fit.transform(X_train)\n",
        "X_test_rfe = fit.transform(X_test)"
      ],
      "metadata": {
        "id": "9cv9I3GcnsZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning using HyperOpt for XGBClassifier  # Also provide the same seeds  #\n",
        "def hyperopt_train_test(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    return cross_val_score(clf, X_train_rfe, y_train.values.ravel(), scoring='recall').mean()\n",
        "\n",
        "space4xgb = {\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
        "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 200, 1)),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n",
        "}"
      ],
      "metadata": {
        "id": "NEKvpeNanvoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(params):\n",
        "    acc = hyperopt_train_test(params)\n",
        "    return {'loss': -acc, 'status': STATUS_OK}\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(f, space4xgb, algo=tpe.suggest, max_evals=50, trials=trials)\n",
        "print('Best hyperparameters:', best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jaOqF0UnxZ8",
        "outputId": "c0d5da0d-67cf-4278-f8dc-4732cb329125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 50/50 [00:29<00:00,  1.70trial/s, best loss: -0.7072727272727273]\n",
            "Best hyperparameters: {'learning_rate': 0.1722949447698182, 'max_depth': 2.0, 'n_estimators': 199.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train XGBClassifier with best hyperparameters\n",
        "best_params = {\n",
        "    'max_depth': int(best['max_depth']),\n",
        "    'n_estimators': int(best['n_estimators']),\n",
        "    'learning_rate': best['learning_rate']\n",
        "}"
      ],
      "metadata": {
        "id": "Zjh8d5UfnzJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgb = XGBClassifier(**best_params)\n",
        "model_xgb.fit(X_train_rfe, y_train.values.ravel())\n",
        "predictions_xgb = model_xgb.predict(X_test_rfe)"
      ],
      "metadata": {
        "id": "dVxeMuadn1kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate XGBClassifier\n",
        "accuracy_xgb = accuracy_score(y_test, predictions_xgb)\n",
        "conf_matrix_xgb = confusion_matrix(y_test, predictions_xgb)\n",
        "class_report_xgb = classification_report(y_test, predictions_xgb)"
      ],
      "metadata": {
        "id": "iGRHhWOFn7o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'XGBClassifier Accuracy: {accuracy_xgb}')\n",
        "print('XGBClassifier Confusion Matrix:')\n",
        "print(conf_matrix_xgb)\n",
        "print('XGBClassifier Classification Report:')\n",
        "print(class_report_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXegQnY3ovBf",
        "outputId": "c269244f-3ffb-4025-83a0-48b734ed868d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier Accuracy: 0.6153846153846154\n",
            "XGBClassifier Confusion Matrix:\n",
            "[[ 5  3]\n",
            " [ 7 11]]\n",
            "XGBClassifier Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.62      0.50         8\n",
            "           1       0.79      0.61      0.69        18\n",
            "\n",
            "    accuracy                           0.62        26\n",
            "   macro avg       0.60      0.62      0.59        26\n",
            "weighted avg       0.67      0.62      0.63        26\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking Classifier\n",
        "estimators = [\n",
        "    ('logreg', LogisticRegression(random_state=seed)),\n",
        "    ('knn', KNeighborsClassifier()),\n",
        "    ('xgb', XGBClassifier(**best_params))\n",
        "]"
      ],
      "metadata": {
        "id": "1CedV0ONoxak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking Classifier\n",
        "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "stacking_clf.fit(X_train_rfe, y_train.values.ravel())\n",
        "predictions_stack = stacking_clf.predict(X_test_rfe)"
      ],
      "metadata": {
        "id": "DFqiQqkOozjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Stacking Classifier\n",
        "accuracy_stack = accuracy_score(y_test, predictions_stack)\n",
        "conf_matrix_stack = confusion_matrix(y_test, predictions_stack)\n",
        "class_report_stack = classification_report(y_test, predictions_stack)"
      ],
      "metadata": {
        "id": "_8HQ2qcBo1Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Stacking Classifier Accuracy: {accuracy_stack}')\n",
        "print('Stacking Classifier Confusion Matrix:')\n",
        "print(conf_matrix_stack)\n",
        "print('Stacking Classifier Classification Report:')\n",
        "print(class_report_stack)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PpPNgkUo2vV",
        "outputId": "e021a669-ef38-474f-852f-efd573bbc262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.5384615384615384\n",
            "Stacking Classifier Confusion Matrix:\n",
            "[[ 6  2]\n",
            " [10  8]]\n",
            "Stacking Classifier Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.75      0.50         8\n",
            "           1       0.80      0.44      0.57        18\n",
            "\n",
            "    accuracy                           0.54        26\n",
            "   macro avg       0.59      0.60      0.54        26\n",
            "weighted avg       0.67      0.54      0.55        26\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Voting Classifier - Soft Voting\n",
        "voting_clf_soft = VotingClassifier(estimators=estimators, voting='soft')\n",
        "voting_clf_soft.fit(X_train_rfe, y_train.values.ravel())\n",
        "predictions_vote_soft = voting_clf_soft.predict(X_test_rfe)"
      ],
      "metadata": {
        "id": "ZUvG82Jjo4Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Soft Voting Classifier\n",
        "accuracy_vote_soft = accuracy_score(y_test, predictions_vote_soft)\n",
        "conf_matrix_vote_soft = confusion_matrix(y_test, predictions_vote_soft)\n",
        "class_report_vote_soft = classification_report(y_test, predictions_vote_soft)"
      ],
      "metadata": {
        "id": "9HKcy22Po5iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Voting Classifier (Soft) Accuracy: {accuracy_vote_soft}')\n",
        "print('Voting Classifier (Soft) Confusion Matrix:')\n",
        "print(conf_matrix_vote_soft)\n",
        "print('Voting Classifier (Soft) Classification Report:')\n",
        "print(class_report_vote_soft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi_oynCmo6tO",
        "outputId": "2e270803-fb29-456a-c3a7-074f77542c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier (Soft) Accuracy: 0.5\n",
            "Voting Classifier (Soft) Confusion Matrix:\n",
            "[[ 3  5]\n",
            " [ 8 10]]\n",
            "Voting Classifier (Soft) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.38      0.32         8\n",
            "           1       0.67      0.56      0.61        18\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.47      0.47      0.46        26\n",
            "weighted avg       0.55      0.50      0.52        26\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Voting Classifier - Soft Voting\n",
        "voting_clf_hard = VotingClassifier(estimators=estimators, voting='hard')\n",
        "voting_clf_hard.fit(X_train_rfe, y_train.values.ravel())\n",
        "predictions_vote_hard = voting_clf_hard.predict(X_test_rfe)"
      ],
      "metadata": {
        "id": "eAnKdGkFo8K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Soft Voting Classifier\n",
        "accuracy_vote_hard = accuracy_score(y_test, predictions_vote_hard)\n",
        "conf_matrix_vote_hard = confusion_matrix(y_test, predictions_vote_hard)\n",
        "class_report_vote_hard = classification_report(y_test, predictions_vote_hard)"
      ],
      "metadata": {
        "id": "htGac0dYo90s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Voting Classifier (Hard) Accuracy: {accuracy_vote_hard}')\n",
        "print('Voting Classifier (Hard) Confusion Matrix:')\n",
        "print(conf_matrix_vote_hard)\n",
        "print('Voting Classifier (Hard) Classification Report:')\n",
        "print(class_report_vote_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD10x-YVOJUs",
        "outputId": "ffe4e731-d40d-4386-eada-3a362ad152b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier (Hard) Accuracy: 0.46153846153846156\n",
            "Voting Classifier (Hard) Confusion Matrix:\n",
            "[[ 2  6]\n",
            " [ 8 10]]\n",
            "Voting Classifier (Hard) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.25      0.22         8\n",
            "           1       0.62      0.56      0.59        18\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.41      0.40      0.41        26\n",
            "weighted avg       0.49      0.46      0.48        26\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusions for 3rd Try:\n",
        "1. Remember, I have to check class 0 for recall since I need to focus on unsatisfactory customers.\n",
        "2. Random seed might affect to the performance, and remember the number once it works well."
      ],
      "metadata": {
        "id": "6Kkc4242rKGp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GwvPKXWfnQB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
