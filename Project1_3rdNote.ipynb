{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1lyLnTtC3N3K2jy_nPqYk4x3muGINGQ2u",
      "authorship_tag": "ABX9TyNhZf/9pUV+1BdDcF/HKCNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinnew99/Apziva-Projects/blob/main/Project1_3rdNote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA_jxDT2MPXA",
        "outputId": "3c745954-4b59-4a91-cd98-b7ea2ea4787e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazypredict"
      ],
      "metadata": {
        "id": "tx3tRxo9nJGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefe0ba2-adc0-4714-cbe3-d908705bb51a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lazypredict in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.1.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.66.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.4.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.4.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost->lazypredict) (2.22.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from xgboost import XGBClassifier\n",
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
        "from hyperopt.pyll.base import scope\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "BS7KWN_6k6hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19d73e2-9e2e-4f98-a5a2-b63257465738"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Apziva/ACME-HappinessSurvey2020.csv')\n",
        "\n",
        "data = df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6']]\n",
        "target = df[['Y']]"
      ],
      "metadata": {
        "id": "9DnaoAjbnVoz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed = random.randint(1000, 9999)\n",
        "seed = 6245\n",
        "print(seed)  # 6245, XGB - racll (0.88) for class 0\n",
        "\n",
        "# run quite a few times, monitor each time to find out better seeds and whether it impacts higher perfermance on class 0, recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykSparmFnagR",
        "outputId": "491263f8-236c-4f1e-a68d-a90c3907f4e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=seed)"
      ],
      "metadata": {
        "id": "gvYKWo3JnkYg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "print(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85NXeg_3noBS",
        "outputId": "a62719bd-be12-49f5-f44a-4516c07b7026"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [00:01<00:00, 17.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 51, number of negative: 49\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 31\n",
            "[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.510000 -> initscore=0.040005\n",
            "[LightGBM] [Info] Start training from score 0.040005\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
            "Model                                                                           \n",
            "LabelPropagation                   0.69               0.71     0.71      0.70   \n",
            "LabelSpreading                     0.69               0.71     0.71      0.70   \n",
            "BernoulliNB                        0.62               0.69     0.69      0.62   \n",
            "LGBMClassifier                     0.58               0.66     0.66      0.58   \n",
            "DecisionTreeClassifier             0.65               0.65     0.65      0.67   \n",
            "BaggingClassifier                  0.65               0.65     0.65      0.67   \n",
            "QuadraticDiscriminantAnalysis      0.58               0.62     0.62      0.59   \n",
            "NuSVC                              0.65               0.61     0.61      0.66   \n",
            "NearestCentroid                    0.54               0.60     0.60      0.55   \n",
            "SVC                                0.54               0.60     0.60      0.55   \n",
            "GaussianNB                         0.54               0.60     0.60      0.55   \n",
            "ExtraTreeClassifier                0.58               0.56     0.56      0.59   \n",
            "RidgeClassifierCV                  0.50               0.53     0.53      0.52   \n",
            "RidgeClassifier                    0.50               0.53     0.53      0.52   \n",
            "AdaBoostClassifier                 0.50               0.53     0.53      0.52   \n",
            "LogisticRegression                 0.50               0.53     0.53      0.52   \n",
            "LinearDiscriminantAnalysis         0.50               0.53     0.53      0.52   \n",
            "CalibratedClassifierCV             0.50               0.53     0.53      0.52   \n",
            "LinearSVC                          0.50               0.53     0.53      0.52   \n",
            "RandomForestClassifier             0.54               0.53     0.53      0.56   \n",
            "XGBClassifier                      0.54               0.53     0.53      0.56   \n",
            "DummyClassifier                    0.69               0.50     0.50      0.57   \n",
            "ExtraTreesClassifier               0.54               0.49     0.49      0.55   \n",
            "SGDClassifier                      0.35               0.49     0.49      0.27   \n",
            "Perceptron                         0.50               0.47     0.47      0.52   \n",
            "KNeighborsClassifier               0.42               0.34     0.34      0.43   \n",
            "PassiveAggressiveClassifier        0.27               0.30     0.30      0.28   \n",
            "\n",
            "                               Time Taken  \n",
            "Model                                      \n",
            "LabelPropagation                     0.02  \n",
            "LabelSpreading                       0.02  \n",
            "BernoulliNB                          0.03  \n",
            "LGBMClassifier                       0.12  \n",
            "DecisionTreeClassifier               0.03  \n",
            "BaggingClassifier                    0.04  \n",
            "QuadraticDiscriminantAnalysis        0.03  \n",
            "NuSVC                                0.04  \n",
            "NearestCentroid                      0.04  \n",
            "SVC                                  0.04  \n",
            "GaussianNB                           0.02  \n",
            "ExtraTreeClassifier                  0.04  \n",
            "RidgeClassifierCV                    0.05  \n",
            "RidgeClassifier                      0.06  \n",
            "AdaBoostClassifier                   0.16  \n",
            "LogisticRegression                   0.04  \n",
            "LinearDiscriminantAnalysis           0.03  \n",
            "CalibratedClassifierCV               0.08  \n",
            "LinearSVC                            0.04  \n",
            "RandomForestClassifier               0.20  \n",
            "XGBClassifier                        0.17  \n",
            "DummyClassifier                      0.03  \n",
            "ExtraTreesClassifier                 0.17  \n",
            "SGDClassifier                        0.05  \n",
            "Perceptron                           0.04  \n",
            "KNeighborsClassifier                 0.02  \n",
            "PassiveAggressiveClassifier          0.04  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursive Feature Elimination (RFE)\n",
        "def perform_rfe(model, X_train, y_train, k):\n",
        "    rfe = RFE(estimator=model, n_features_to_select=k)\n",
        "    fit = rfe.fit(X_train, y_train.values.ravel())\n",
        "    return fit"
      ],
      "metadata": {
        "id": "OwUgjw5nnqyi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-k features based on RFE\n",
        "rfe_model = LogisticRegression()  # make sure I'm using the same seeds for the models\n",
        "fit = perform_rfe(rfe_model, X_train, y_train, 3)  # selecting top 3 features for simplicity  # I need to print out the name of the features, so that I can recommend to the companies\n",
        "# print out the ranking\n",
        "X_train_rfe = fit.transform(X_train)\n",
        "X_test_rfe = fit.transform(X_test)"
      ],
      "metadata": {
        "id": "9cv9I3GcnsZY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning using HyperOpt for XGBClassifier  # Also provide the same seeds  #\n",
        "def hyperopt_train_test(params):\n",
        "    clf = XGBClassifier(**params)\n",
        "    return cross_val_score(clf, X_train_rfe, y_train.values.ravel(), scoring='recall').mean()\n",
        "\n",
        "space4xgb = {\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
        "    'n_estimators': scope.int(hp.quniform('n_estimators', 10, 200, 1)),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n",
        "}"
      ],
      "metadata": {
        "id": "NEKvpeNanvoi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(params):\n",
        "    acc = hyperopt_train_test(params)\n",
        "    return {'loss': -acc, 'status': STATUS_OK}\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(f, space4xgb, algo=tpe.suggest, max_evals=50, trials=trials)\n",
        "print('Best hyperparameters:', best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jaOqF0UnxZ8",
        "outputId": "ee1f12f8-2e63-4506-c6d9-f02531f035e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 50/50 [00:26<00:00,  1.87trial/s, best loss: -0.7090909090909092]\n",
            "Best hyperparameters: {'learning_rate': 0.013107676729493896, 'max_depth': 1.0, 'n_estimators': 79.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train XGBClassifier with best hyperparameters\n",
        "best_params = {\n",
        "    'max_depth': int(best['max_depth']),\n",
        "    'n_estimators': int(best['n_estimators']),\n",
        "    'learning_rate': best['learning_rate']\n",
        "}"
      ],
      "metadata": {
        "id": "Zjh8d5UfnzJx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgb = XGBClassifier(**best_params)\n",
        "model_xgb.fit(X_train_rfe, y_train.values.ravel())\n",
        "predictions_xgb = model_xgb.predict(X_test_rfe)"
      ],
      "metadata": {
        "id": "dVxeMuadn1kq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate XGBClassifier\n",
        "accuracy_xgb = accuracy_score(y_test, predictions_xgb)\n",
        "conf_matrix_xgb = confusion_matrix(y_test, predictions_xgb)\n",
        "class_report_xgb = classification_report(y_test, predictions_xgb)"
      ],
      "metadata": {
        "id": "iGRHhWOFn7o9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'XGBClassifier Accuracy: {accuracy_xgb}')\n",
        "print('XGBClassifier Confusion Matrix:')\n",
        "print(conf_matrix_xgb)\n",
        "print('XGBClassifier Classification Report:')\n",
        "print(class_report_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXegQnY3ovBf",
        "outputId": "7280cfa4-47ff-4192-c8b4-317f121c881a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier Accuracy: 0.6153846153846154\n",
            "XGBClassifier Confusion Matrix:\n",
            "[[7 1]\n",
            " [9 9]]\n",
            "XGBClassifier Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.88      0.58         8\n",
            "           1       0.90      0.50      0.64        18\n",
            "\n",
            "    accuracy                           0.62        26\n",
            "   macro avg       0.67      0.69      0.61        26\n",
            "weighted avg       0.76      0.62      0.62        26\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking Classifier\n",
        "estimators = [\n",
        "    ('logreg', LogisticRegression(random_state=seed)),\n",
        "    ('knn', KNeighborsClassifier()),\n",
        "    ('xgb', XGBClassifier(**best_params))\n",
        "]"
      ],
      "metadata": {
        "id": "1CedV0ONoxak"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking Classifier\n",
        "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "stacking_clf.fit(X_train_rfe, y_train.values.ravel())\n",
        "predictions_stack = stacking_clf.predict(X_test_rfe)"
      ],
      "metadata": {
        "id": "DFqiQqkOozjV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Stacking Classifier\n",
        "accuracy_stack = accuracy_score(y_test, predictions_stack)\n",
        "conf_matrix_stack = confusion_matrix(y_test, predictions_stack)\n",
        "class_report_stack = classification_report(y_test, predictions_stack)"
      ],
      "metadata": {
        "id": "_8HQ2qcBo1Am"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Stacking Classifier Accuracy: {accuracy_stack}')\n",
        "print('Stacking Classifier Confusion Matrix:')\n",
        "print(conf_matrix_stack)\n",
        "print('Stacking Classifier Classification Report:')\n",
        "print(class_report_stack)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PpPNgkUo2vV",
        "outputId": "b2e7709a-db02-4a81-86b1-334942a81118"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.46153846153846156\n",
            "Stacking Classifier Confusion Matrix:\n",
            "[[ 4  4]\n",
            " [10  8]]\n",
            "Stacking Classifier Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.50      0.36         8\n",
            "           1       0.67      0.44      0.53        18\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.48      0.47      0.45        26\n",
            "weighted avg       0.55      0.46      0.48        26\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Voting Classifier - Soft Voting\n",
        "voting_clf_soft = VotingClassifier(estimators=estimators, voting='soft')\n",
        "voting_clf_soft.fit(X_train_rfe, y_train.values.ravel())\n",
        "predictions_vote_soft = voting_clf_soft.predict(X_test_rfe)"
      ],
      "metadata": {
        "id": "ZUvG82Jjo4Uf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Soft Voting Classifier\n",
        "accuracy_vote_soft = accuracy_score(y_test, predictions_vote_soft)\n",
        "conf_matrix_vote_soft = confusion_matrix(y_test, predictions_vote_soft)\n",
        "class_report_vote_soft = classification_report(y_test, predictions_vote_soft)"
      ],
      "metadata": {
        "id": "9HKcy22Po5iP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Voting Classifier (Soft) Accuracy: {accuracy_vote_soft}')\n",
        "print('Voting Classifier (Soft) Confusion Matrix:')\n",
        "print(conf_matrix_vote_soft)\n",
        "print('Voting Classifier (Soft) Classification Report:')\n",
        "print(class_report_vote_soft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi_oynCmo6tO",
        "outputId": "31734ce7-3d76-4b7e-feaf-599abb584bf1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier (Soft) Accuracy: 0.5\n",
            "Voting Classifier (Soft) Confusion Matrix:\n",
            "[[ 3  5]\n",
            " [ 8 10]]\n",
            "Voting Classifier (Soft) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.38      0.32         8\n",
            "           1       0.67      0.56      0.61        18\n",
            "\n",
            "    accuracy                           0.50        26\n",
            "   macro avg       0.47      0.47      0.46        26\n",
            "weighted avg       0.55      0.50      0.52        26\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Voting Classifier - Soft Voting\n",
        "voting_clf_hard = VotingClassifier(estimators=estimators, voting='hard')\n",
        "voting_clf_hard.fit(X_train_rfe, y_train.values.ravel())\n",
        "predictions_vote_hard = voting_clf_hard.predict(X_test_rfe)"
      ],
      "metadata": {
        "id": "eAnKdGkFo8K2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Soft Voting Classifier\n",
        "accuracy_vote_hard = accuracy_score(y_test, predictions_vote_hard)\n",
        "conf_matrix_vote_hard = confusion_matrix(y_test, predictions_vote_hard)\n",
        "class_report_vote_hard = classification_report(y_test, predictions_vote_hard)"
      ],
      "metadata": {
        "id": "htGac0dYo90s"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Voting Classifier (Hard) Accuracy: {accuracy_vote_hard}')\n",
        "print('Voting Classifier (Hard) Confusion Matrix:')\n",
        "print(conf_matrix_vote_hard)\n",
        "print('Voting Classifier (Hard) Classification Report:')\n",
        "print(class_report_vote_hard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD10x-YVOJUs",
        "outputId": "d66c35e1-e90e-4284-a506-03d49e59ef2f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier (Hard) Accuracy: 0.46153846153846156\n",
            "Voting Classifier (Hard) Confusion Matrix:\n",
            "[[ 4  4]\n",
            " [10  8]]\n",
            "Voting Classifier (Hard) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.50      0.36         8\n",
            "           1       0.67      0.44      0.53        18\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.48      0.47      0.45        26\n",
            "weighted avg       0.55      0.46      0.48        26\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GwvPKXWfnQB2"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}